{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastiantonn/phd/blob/main/chapter3/04_deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Tl7aq_T7-RJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3b8b8d-864e-46ae-cbd5-a221d7c37047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "import itertools\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "REq7QNVf7CyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable built-in DOS attack protection of PIL to accomodate large input image size\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# Load the trained neural network and weights\n",
        "TrypanBlueModel = keras.models.load_model('/content/drive/MyDrive/PhD/TrypanBlue/240225-03_trypan-blue_VGG16_adamax_AP60-checkpoints/TrypanBlueModel.keras')\n",
        "TrypanBlueModel.load_weights('/content/drive/MyDrive/PhD/TrypanBlue/240225-03_trypan-blue_VGG16_adamax_AP60-checkpoints/weights_19-0.08.hdf5')"
      ],
      "metadata": {
        "id": "Xx2YcRIr7Fyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tile size that the leaf disc image will be split into.\n",
        "# The model was trained using 400x400 tiles that were rescaled to 224 x 224 during the preprocessing phase.\n",
        "# 224 x 224 rescaling will occur here as well prior to prediction.\n",
        "tile_size = 480 # 500 (or 480) pixel for new 2023 image set?\n",
        "\n",
        "# Define the threshold value with which to find the largest contour in the image\n",
        "# This is how the program finds the region of interest.\n",
        "# 200 is the default\n",
        "thresh_value = 200\n",
        "\n",
        "# Define the radius of the region of interest (ROI) from the center of the disc.\n",
        "# This is how the program segregates tiles that are within the ROI from those that are outside of it.\n",
        "# 5800 is the default\n",
        "radius = 6800 # 7300 (or 6800) for new leaf disc images taken in 2023, 5800 for old images"
      ],
      "metadata": {
        "id": "a1MbxY5d-lxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINE THE INPUT FOLDER that contains the images of leaf discs\n",
        "\n",
        "# IMPORTANT NOTE: The images must be saved with file names in the following format with a .jpg extension:\n",
        "\n",
        "#      \"genotype_Xdpi_pathogen_Y-?????.jpg\"\n",
        "\n",
        "#       2023 data set has a different format:\n",
        "#       \"bedford_a_24_2dpi_1_Stitching.jpg\"\n",
        "\n",
        "#   where\n",
        "#       'genotype' = The host variety name.\n",
        "#                    If the variety name normally contains a space, replace the space with a dash(\"-\")\n",
        "\n",
        "#        X = an integer representing the days after inoculation, follow this integer with 'dpi' - no spaces\n",
        "\n",
        "#       'pathogen' = pathogen information; spaces should be replaced by \"-\"\n",
        "\n",
        "#        Y = an integer representing the replicate number.\n",
        "#            If there are no replicates, the filename must still contain a \"1\" here.\n",
        "\n",
        "#        -????? = Any further identifying information about the file.\n",
        "#                 Include the dash (\"-\") but otherwise, special charachters are not allowed.\n",
        "\n",
        "# EXAMPLE: \"grand-rapids_3dpi_Bl33_1-stitch.jpg\"\n",
        "\n",
        "# The filename format (especially the order and the underscores) is important because the script\n",
        "#     will automatically deposit that information into a dictionary for later analysis.\n",
        "\n",
        "# Indicate where the subdirectories are located.\n",
        "base_dir = '/content/drive/MyDrive/PhD/TrypanBlue/240226_model-deploy/'\n",
        "\n",
        "# Indicate the subdirectory that contains images of whole leaf discs\n",
        "disc_img_dir = '/content/drive/MyDrive/PhD/TrypanBlue/240226_model-deploy/trypanblue_2023set_JPG' # The subdirectory that contains images of whole leaf discs\n"
      ],
      "metadata": {
        "id": "0db6cbMq-rm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define, and if necessary create, output folders\n",
        "\n",
        "# Directory to save model predictions per tile for each image\n",
        "pred_csv_dir = base_dir + 'tile_prediction_csv'\n",
        "if not os.path.isdir(pred_csv_dir):\n",
        "    os.mkdir(pred_csv_dir)\n",
        "\n",
        "# Directory to save images with annotations indicating which tiles are predicted to contain hyphae\n",
        "img_out_dir = base_dir + 'model_output_images'\n",
        "if not os.path.isdir(img_out_dir):\n",
        "    os.mkdir(img_out_dir)\n",
        "\n",
        "results_dir = base_dir + 'CNN-240225-03_test.csv'"
      ],
      "metadata": {
        "id": "-Q0EBQVTzoMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsDfyzKMjEgI"
      },
      "outputs": [],
      "source": [
        "# CREATE A NESTED DICTIONARY to store all the information for each leaf disc and its corresponding tiles\n",
        "# Note that since Python v3.7, dictionaries are now ordered.\n",
        "\n",
        "# The structure of the nested dictionary will be:\n",
        "\n",
        "# 'exp_dict'\n",
        "#   KEY = 'Image_ID' - The name of the image file without an extension; parent key, the values for which are two subdictionaries.\n",
        "#   VALUE = 'disc_dict'\n",
        "#      where 'disc_dict' =\n",
        "#          'disc_filename' = leaf disc filename. IF THERE ARE DUPLICATE FILE NAMES, THEN ONLY THE LAST ONE THROUGH THE LOOP WILL BE RECORDED\n",
        "#          'local_path' = base_dir/disc_img_dir/disc_filename.jpg\n",
        "#          'file_extension' = should be .jpg for all discs\n",
        "#          'img_shape' = image dimensions in pixels (height, width, channels)\n",
        "#          'variety' = host variety. Uppercase enforced.\n",
        "#          'pathogen' = pathogen id. Uppercase enforced.\n",
        "#          'dpi' = integer of days post inoculation\n",
        "#          'rep_number' = the integer of the technical replicate\n",
        "#          'ROI_tile_count' = total number of 400 x 400 px tiles within the determined region of interest\n",
        "#          'ROI_hyphae_count' = number of 400 x 400 px tiles within the determined region of interest that are predicted by the model to contain hyphae\n",
        "#          'infection_frequency' = the proportion of tiles within the region of interest that are predicted to contain hyphae.\n",
        "#                                  Expressed as a float between 0 and 1.\n",
        "\n",
        "\n",
        "# 'tile_dict' = a separate dictionary of tile information and the model output prediction for each leaf disc\n",
        "#               This is kept separate for ease and cleanliness of data output to .csv later\n",
        "\n",
        "#      KEY: ('tile_pt1', 'tile_pt2') = tuple representing the two opposing coordinate points that create a tile\n",
        "#      VALUE: 'hyphae_prediction' = model prediction float that the tile contains hyphae\n",
        "\n",
        "\n",
        "# create lists that contain the keys for the 'disc_dict'\n",
        "disc_keys = ['disc_filename', 'local_path', 'file_extension', 'img_shape', 'variety', 'pathogen', 'dpi', 'batch', 'rep_number']\n",
        "# the 'ROI_tile_count', 'ROI_hyphae_count','infection_frequency' will be added later\n",
        "# the individual tile predictions will go to a separate dictionary\n",
        "\n",
        "# Create an empty dictionary. This is the top layer dictionary that will have Image_IDs as the keys.\n",
        "exp_dict = {}\n",
        "\n",
        "# Loop through the 'disc_img_dir' and extract values for the Image_ID keys and the subdictionary values.\n",
        "for subdir, dirs, files in os.walk(disc_img_dir):\n",
        "    for file in files:\n",
        "        filepath = subdir + os.sep + file\n",
        "        if filepath.endswith(\".jpg\") or filepath.endswith(\".jpeg\"):\n",
        "\n",
        "            # Create empty dictionaries for the technical and biological information\n",
        "            technical_info = {}\n",
        "            biological_info = {}\n",
        "\n",
        "            # Create an empty dictionary for the individual tile predictions.   \"bedford_a_24_2dpi_1_Stitching.jpg\"\n",
        "            tile_dict = {}\n",
        "\n",
        "            # Extract the values\n",
        "            disc_filename = file\n",
        "            Image_ID = file.split('.')[0]\n",
        "            local_path = filepath\n",
        "            file_extension = os.path.splitext(file)[1]\n",
        "            img = cv.imread(filepath)\n",
        "            img_shape = img.shape\n",
        "\n",
        "            variety = file.split('_')[0]\n",
        "            if len(re.findall(\"-\", variety)) > 0:\n",
        "                variety = re.sub(\"-\", \" \", variety)\n",
        "                variety = variety.upper()\n",
        "            else:\n",
        "                variety = variety.upper()\n",
        "\n",
        "            pathogen = file.split('_')[2]\n",
        "            if len(re.findall(\"-\", pathogen)) > 0:\n",
        "                pathogen = re.sub(\"-\", \" \", pathogen)\n",
        "                pathogen = pathogen.upper()\n",
        "            else:\n",
        "                pathogen = pathogen.upper()\n",
        "\n",
        "            dpi_first_cut = file.split('_')[3]\n",
        "            dpi = ''.join(d for d in dpi_first_cut if d.isdigit())\n",
        "            dpi = int(dpi)\n",
        "            rep_number_first_cut = file.split('_')[4]\n",
        "            rep_number = rep_number_first_cut.split('-')[0]\n",
        "\n",
        "            batch = file.split('_')[1]\n",
        "\n",
        "            # Add the values to the appropriate subdictionary\n",
        "            disc_values = [disc_filename, local_path, file_extension, img_shape, variety, pathogen, dpi, batch, rep_number]\n",
        "            disc_zip = zip(disc_keys, disc_values)\n",
        "            disc_dict = dict(disc_zip)\n",
        "\n",
        "            # Create a variable that stores the total amount of tiles within the ROI:\n",
        "            ROI_tile_count = 0\n",
        "            # Create a variable that stores the total amount of tiles within the ROI that are predicted to have hyphae in them\n",
        "            ROI_hyphae_count = 0\n",
        "\n",
        "            # NEXT STEPS:\n",
        "            #   1. FIND THE REGION OF INTEREST\n",
        "            #   2. SLICE THE IMAGE ALONG A 400 x 400 GRID\n",
        "            #   3. ONLY RUN THOSE TILES THAT FALL COMPLETELY WITHIN THE REGION OF INTEREST THROUGH THE TRAINED CNN\n",
        "            #   5. OUTPUT THE COORDINATES AND PREDICTION FOR EACH TILE INTO THE SECOND LAYER OF THE 'exp_dict' AS A VALUE FOR THE 'tile_predictions' KEY.\n",
        "\n",
        "            # Create an empty dictionary that will store the tile coordinates and prediction values for all tiles within the region of interest of the disc\n",
        "            tile_dict = {}\n",
        "\n",
        "            # Define var 'img_PIL' as the image to be tiled, open the image file.\n",
        "            img_PIL = Image.open(filepath)\n",
        "\n",
        "            # Define var 'img_cv' as the image to be interpreted as a numpy array and analyzed for contours.\n",
        "            # This was alread performed - re-assigned to 'img_cv' for clarity\n",
        "            img_cv = img\n",
        "\n",
        "            # Convert the RGB image 'img_cv' to grayscale.\n",
        "            gray = cv.cvtColor(img_cv, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Apply threshold to the inverted grayscale 'img_cv'.\n",
        "            retval, thresh_gray = cv.threshold(gray, thresh=thresh_value, maxval=255, type=cv.THRESH_BINARY_INV)\n",
        "\n",
        "            # Use the threshold to generate a list of all the objects in 'img_cv'.\n",
        "            contours, hierarchy = cv.findContours(thresh_gray, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            # Find object with the biggest bounding box\n",
        "            mx = (0,0,0,0)      # biggest bounding box so far\n",
        "            mx_area = 0\n",
        "            for cont in contours: #iterate through the list of objects to find the biggest one.\n",
        "                x,y,w,h = cv.boundingRect(cont)\n",
        "                area = w*h\n",
        "                if area > mx_area:\n",
        "                    mx = x,y,w,h\n",
        "                    mx_area = area\n",
        "            x,y,w,h = mx\n",
        "            # 'mx' = the coordinates that correspond to the rectangular bounding box that encompasses the largest object\n",
        "            # (i.e. the leaf disc)\n",
        "\n",
        "            # Calculate x,y coordinate of the center of the largest contour in 'img_cv'\n",
        "            centerCoord = (mx[0]+(mx[2]/2), mx[1]+(mx[3]/2))\n",
        "\n",
        "            # Extract the X and Y coordinate of the ROI center\n",
        "            cX = int(centerCoord[0])\n",
        "            cY = int(centerCoord[1])\n",
        "\n",
        "            # Define the grid lines (as a list) within the range of the largest contour along which the tiling cuting will be made\n",
        "            # Note: partial tiles are ignored\n",
        "            grid = list(itertools.product(range(y, h - h%tile_size, tile_size), range(x, w-w%tile_size, tile_size)))\n",
        "\n",
        "            for i, j in grid: # Iterate through the list 'grid'\n",
        "\n",
        "                # Use the 'grid' list to make a tile with dimensions according to 'tile_size' argument\n",
        "                tile = (j, i, j + tile_size, i + tile_size)\n",
        "\n",
        "                # determine how far away the farthest point of each tile is from the center of the area of interest\n",
        "                dx = max(abs(cX - j), abs((j+tile_size)- cX))\n",
        "                dy = max(abs(cY - i), abs((i+tile_size)- cY))\n",
        "\n",
        "                # Draw the bounding box and region of interest onto the whole leaf disc image\n",
        "                cv.circle(img_cv, (cX, cY), radius, (0, 0, 0), 10)\n",
        "                cv.rectangle(img_cv,(x,y),(x+w,y+h),(0, 0, 0),10)\n",
        "\n",
        "                # Use the Pythagorean theorum to determine if the the furthest point of each tile\n",
        "                # is within our circular area of interest, which has a user-defined radius\n",
        "                # and whose center is derived from the center of the rectangular bounding box.\n",
        "                if radius*radius >= (dx * dx) + (dy * dy):\n",
        "\n",
        "                    # Add 1 to the count of total ROI_tiles\n",
        "                    ROI_tile_count += 1\n",
        "\n",
        "                    # Save the 'y_px_range' values (min, max)\n",
        "                    tile_pt1 = (j, i)\n",
        "\n",
        "                    # Save the 'x_px_range' values (min, max)\n",
        "                    tile_pt2 = (j + tile_size, i + tile_size)\n",
        "\n",
        "                    # Fetch that slice of the original disc image and load it into Keras' image module.\n",
        "                    tile_PIL = img_PIL.crop(tile)\n",
        "                    tile_resized = tile_PIL.resize((224, 224), resample = 1)\n",
        "\n",
        "                    # Perform preprocessing steps for the model\n",
        "                    tile_array = image.img_to_array(tile_resized)\n",
        "                    tile_array_batched = np.expand_dims(tile_array, axis = 0)\n",
        "                    tile_preprocessed = preprocess_input(tile_array_batched)\n",
        "\n",
        "                    # Run it through the trained neural netork to get the model's prediction\n",
        "                    hyphae_prediction = TrypanBlueModel.predict(tile_preprocessed, verbose = 0)\n",
        "\n",
        "                    # Create a dictionary element for every tile in the region of interest and store it in the 'tile_dict' dictionary\n",
        "                    # The key will be the tuple of tile coordinates and the value will be the float of the prediction values generated by the model.\n",
        "                    tile_coordinates = tile_pt1, tile_pt2\n",
        "                    tile_coordinates = str(tile_coordinates)\n",
        "                    tile_dict[tile_coordinates] = hyphae_prediction[0][0]\n",
        "\n",
        "                    # Represent the prediction of each tile as a color-coded rectangle drawn onto the whole leaf-disc image\n",
        "                    if hyphae_prediction[0][0] >= 0.5:\n",
        "                      cv.rectangle(img_cv, pt1 = tile_pt1, pt2 = tile_pt2, color = (150, 20, 255),thickness = 20)\n",
        "\n",
        "                      # Add 1 to the count of ROI tiles that are predicted to contain hyphae\n",
        "                      ROI_hyphae_count += 1\n",
        "\n",
        "            # Write the tile_dict to a csv file with the filename equal to the Image_ID + .csv\n",
        "            tile_df = pd.DataFrame.from_dict(data = tile_dict, orient = 'index')\n",
        "            tile_csv_name = str(Image_ID) + '.csv'\n",
        "            tile_df.to_csv(os.path.join(pred_csv_dir, tile_csv_name), header = ['hyphae_prediction'])\n",
        "\n",
        "            # Add the 'ROI_tile_counts' to the 'disc_dict' dictionary\n",
        "            disc_dict['ROI_tile_count'] = ROI_tile_count\n",
        "            disc_dict['ROI_hyphae_count'] = ROI_hyphae_count\n",
        "\n",
        "            # Calculate the frequency of tiles within the ROI that are predicted to contain hyphae\n",
        "            infection_frequency = (ROI_hyphae_count / ROI_tile_count)\n",
        "            perc_inf_freq = infection_frequency *100 # Used in the image output\n",
        "\n",
        "            # and store it in the dictionary\n",
        "            disc_dict['infection_frequency'] = infection_frequency\n",
        "\n",
        "            # set the 'disc_dict' as the value for the 'Image_ID' key in the 'exp_dict'\n",
        "            exp_dict[Image_ID] = disc_dict\n",
        "\n",
        "            # Include some biological information as text on the edited image.\n",
        "            cv.putText(img_cv,('Image ID: ' + Image_ID), (x,400), cv.FONT_HERSHEY_PLAIN, 10, (0,0,0), 12)\n",
        "            cv.putText(img_cv,(('Variety: ' + variety + '     B. lactucae race: ' + pathogen)), (x,600), cv.FONT_HERSHEY_PLAIN, 10, (0,0,0), 12)\n",
        "            cv.putText(img_cv,('DPI: ' + str(dpi) + '     %Infected Tiles: ' + str(round(perc_inf_freq, 2))), (x,800), cv.FONT_HERSHEY_PLAIN, 10, (0,0,0), 12)\n",
        "\n",
        "            # Save the image of the leaf disc that has bounding box, region of interest, and hyphae predictions drawn onto it.\n",
        "            cv.imwrite(os.path.join(img_out_dir, f'{Image_ID}_{file_extension}'), img_cv)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the exp_dict to a csv file\n",
        "exp_df = pd.DataFrame.from_dict(data = exp_dict, orient = 'index')\n",
        "exp_df.to_csv(results_dir, header = True)"
      ],
      "metadata": {
        "id": "wWJH9S-UodpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}